{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b24eebc",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Transfer Learning is a machine learning technique where a model trained on one task is reused as the starting point for a model on a second, related task. This approach is particularly useful when there is a lack of large datasets for the new task. Key concepts include:\n",
    "\n",
    "Pretrained Models: Models like VGG16, ResNet, or BERT that are trained on large datasets and can be fine-tuned for specific tasks.\n",
    "\n",
    "Fine-Tuning: Adjusting the weights of the pretrained model to better suit the specific task.\n",
    "\n",
    "Feature Extraction: Using the pretrained model as a fixed feature extractor by removing the final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d81afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the VGG16 model, excluding the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the pretrained model\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Placeholder for data preparation and training\n",
    "# train_generator = ImageDataGenerator(...).flow_from_directory(...)\n",
    "# model.fit(train_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902c750",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Synthetic Data Generation:\n",
    "\n",
    "X: A numpy array of random images with shape (num_samples, 224, 224, 3) representing 1000 random images of size 224x224 with 3 color channels.\n",
    "\n",
    "y: Random labels generated using np.random.randint and converted to one-hot encoding using to_categorical.\n",
    "Data Splitting:\n",
    "\n",
    "train_test_split is used to divide the data into 80% training and 20% validation sets.\n",
    "\n",
    "VGG16 Model:\n",
    "The VGG16 model is loaded without the top layers, and custom fully connected layers are added for classification.\n",
    "The VGG16 layers are frozen to prevent them from being trained.\n",
    "\n",
    "Model Training:\n",
    "The model is trained on the static training data (X_train and y_train) and validated on the validation data (X_val and y_val) for 10 epochs.\n",
    "\n",
    "Model Saving:\n",
    "The trained model is saved as vgg16_transfer_learning_static_data.h5.\n",
    "\n",
    "Evaluation:\n",
    "The model's performance is evaluated on the validation set.\n",
    "\n",
    "Prediction:\n",
    "A random single image is generated, and the model predicts its class.\n",
    "\n",
    "Important Notes:\n",
    "Synthetic Data: This program uses randomly generated data. In practice, you would replace X and y with your actual dataset.\n",
    "Classes: Adjust num_classes if your dataset has a different number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a09161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 13s/step - accuracy: 0.0950 - loss: 3.1716 - val_accuracy: 0.0650 - val_loss: 2.3719\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 12s/step - accuracy: 0.1095 - loss: 2.3123 - val_accuracy: 0.0750 - val_loss: 2.3471\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 11s/step - accuracy: 0.1139 - loss: 2.2968 - val_accuracy: 0.0700 - val_loss: 2.3026\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 12s/step - accuracy: 0.1066 - loss: 2.3021 - val_accuracy: 0.0950 - val_loss: 2.3028\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 11s/step - accuracy: 0.1190 - loss: 2.3014 - val_accuracy: 0.0700 - val_loss: 2.3031\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 11s/step - accuracy: 0.1255 - loss: 2.3010 - val_accuracy: 0.1050 - val_loss: 2.3034\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 11s/step - accuracy: 0.1278 - loss: 2.3004 - val_accuracy: 0.1050 - val_loss: 2.3037\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 11s/step - accuracy: 0.1193 - loss: 2.3000 - val_accuracy: 0.1050 - val_loss: 2.3041\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 11s/step - accuracy: 0.1265 - loss: 2.2981 - val_accuracy: 0.1050 - val_loss: 2.3045\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 11s/step - accuracy: 0.1168 - loss: 2.2989 - val_accuracy: 0.1050 - val_loss: 2.3049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.1032 - loss: 2.3043\n",
      "Validation Loss: 2.3049, Validation Accuracy: 0.1050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Predicted class: 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Create synthetic data\n",
    "num_samples = 1000\n",
    "num_classes = 10\n",
    "\n",
    "# Generate random images and labels\n",
    "X = np.random.rand(num_samples, 224, 224, 3)  # Random images\n",
    "y = np.random.randint(0, num_classes, num_samples)  # Random labels\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y = to_categorical(y, num_classes)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the VGG16 model, excluding the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the pretrained model\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # 10 output classes\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with static data\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('vgg16_transfer_learning_static_data.h5')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Make predictions on a single sample\n",
    "sample = np.random.rand(1, 224, 224, 3)  # Random single image\n",
    "prediction = model.predict(sample)\n",
    "print(\"Predicted class:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c340c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
